{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Autism Screening Tool — ML Training (Google Colab)\n",
        "\n",
        "This notebook runs your **age-specific training pipeline** in Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Install dependencies\n",
        "!pip install -q pandas numpy scikit-learn matplotlib seaborn scipy joblib imbalanced-learn\n",
        "\n",
        "print('OK: packages installed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Upload ZIPs\n",
        "# Upload: ML_TRAINING.zip, Online_Datasets.zip, (optional) SAMPLE_DATASETS.zip\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print('Upload ML_TRAINING.zip, Online_Datasets.zip, and optionally SAMPLE_DATASETS.zip')\n",
        "uploaded = files.upload()\n",
        "\n",
        "for name in uploaded.keys():\n",
        "    if not name.lower().endswith('.zip'):\n",
        "        print('Skipping non-zip:', name)\n",
        "        continue\n",
        "    with zipfile.ZipFile(name, 'r') as z:\n",
        "        z.extractall('/content')\n",
        "    print('Extracted:', name)\n",
        "\n",
        "print('OK: uploads extracted to /content')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Fix folder names / paths and verify expected files\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Sometimes ZIPs create an extra top-level folder. This tries to find ML_TRAINING.\n",
        "content_root = Path('/content')\n",
        "\n",
        "candidates = list(content_root.rglob('ML_TRAINING'))\n",
        "if len(candidates) == 0:\n",
        "    raise FileNotFoundError('Could not find ML_TRAINING folder under /content. Check your ZIP contents.')\n",
        "\n",
        "# Prefer the shortest path\n",
        "ml_training_dir = sorted(candidates, key=lambda p: len(str(p)))[0]\n",
        "print('ML_TRAINING found at:', ml_training_dir)\n",
        "\n",
        "# Find Online Datasets folder\n",
        "online_candidates = list(content_root.rglob('Online Datasets'))\n",
        "online_dir = sorted(online_candidates, key=lambda p: len(str(p)))[0] if online_candidates else None\n",
        "print('Online Datasets found at:', online_dir)\n",
        "\n",
        "# Find SAMPLE_DATASETS folder (optional)\n",
        "sample_candidates = list(content_root.rglob('SAMPLE_DATASETS'))\n",
        "sample_dir = sorted(sample_candidates, key=lambda p: len(str(p)))[0] if sample_candidates else None\n",
        "print('SAMPLE_DATASETS found at:', sample_dir)\n",
        "\n",
        "# Change directory to ML_TRAINING\n",
        "os.chdir(ml_training_dir)\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "required = [\n",
        "    'config.py',\n",
        "    'preprocessing/prepare_age_2_3_5_data.py',\n",
        "    'training/train_age_2_3_5_model.py',\n",
        "    'utils/data_augmentation.py',\n",
        "]\n",
        "\n",
        "for f in required:\n",
        "    print(('OK ' if Path(f).exists() else 'MISSING '), f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Prepare Age 2–3.5 datasets (creates train + test CSVs)\n",
        "# If you did NOT upload SAMPLE_DATASETS.zip, the test set may be empty.\n",
        "!python preprocessing/prepare_age_2_3_5_data.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Train Age 2–3.5 model (trains + evaluates automatically)\n",
        "!python training/train_age_2_3_5_model.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 6: (Optional) Prepare + Train the other age-group models\n",
        "# NOTE: These require you to have prepared game CSVs:\n",
        "# - SAMPLE_DATASETS/prepared/game_age_3_5_5_5_frog_jump.csv\n",
        "# - SAMPLE_DATASETS/prepared/game_age_5_5_6_9_color_shape.csv\n",
        "\n",
        "# Prepare auxiliary questionnaire datasets\n",
        "!python preprocessing/prepare_age_3_5_5_5_data.py\n",
        "!python preprocessing/prepare_age_5_5_6_9_data.py\n",
        "\n",
        "# Train (will warn/fail if the game CSVs are not present)\n",
        "!python training/train_age_3_5_5_5_model.py\n",
        "!python training/train_age_5_5_6_9_model.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 7: Download trained models + results\n",
        "from google.colab import files\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_name = 'trained_models_and_results.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_name, 'w') as z:\n",
        "    # models/\n",
        "    for root, dirs, fs in os.walk('models'):\n",
        "        for f in fs:\n",
        "            z.write(os.path.join(root, f))\n",
        "    # output/\n",
        "    for root, dirs, fs in os.walk('output'):\n",
        "        for f in fs:\n",
        "            z.write(os.path.join(root, f))\n",
        "\n",
        "print('Created:', zip_name)\n",
        "files.download(zip_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Autism Screening Tool — ML Training (Google Colab)\n",
        "\n",
        "This notebook runs your **age-specific training pipeline** in Colab.\n",
        "\n",
        "## What you will upload\n",
        "- `ML_TRAINING.zip` (zip of your `ML_TRAINING/` folder)\n",
        "- `Online_Datasets.zip` (zip of your `Online Datasets/` folder)\n",
        "- (Optional) `SAMPLE_DATASETS.zip` (zip of your `SAMPLE_DATASETS/` folder, if you want to include hospital test data)\n",
        "\n",
        "## What this notebook will produce\n",
        "- Trained models saved under: `ML_TRAINING/models/`\n",
        "- Training outputs saved under: `ML_TRAINING/output/`\n",
        "- A downloadable zip: `trained_models_and_results.zip`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Install dependencies\n",
        "!pip install -q pandas numpy scikit-learn matplotlib seaborn scipy joblib imbalanced-learn\n",
        "\n",
        "print('OK: packages installed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
