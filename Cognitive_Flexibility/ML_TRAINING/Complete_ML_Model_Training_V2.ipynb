{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ§  Complete ASD Screening ML Model Training v2\n",
        "\n",
        "## Master Dataset Training with Sample Weighting\n",
        "\n",
        "This notebook implements the **complete ML training pipeline v2** with:\n",
        "- âœ… Master dataset (real + synthetic data)\n",
        "- âœ… Sample weighting (real data > synthetic)\n",
        "- âœ… Age-normalized feature engineering\n",
        "- âœ… Proper train/validation/test split\n",
        "- âœ… Test evaluation on real data only\n",
        "- âœ… Model calibration and comprehensive evaluation\n",
        "\n",
        "### Key Improvements from v1:\n",
        "- **Sample Weighting**: Real data weighted 3.3Ã— higher than synthetic\n",
        "- **Proper Validation**: Separate validation set for model selection\n",
        "- **Real Data Testing**: Final evaluation only on real clinical data\n",
        "- **Reproducible**: Fixed random seeds for reproducibility\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup and Install Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (Google Colab)\n",
        "# Skip this if using local Jupyter\n",
        "!pip install pandas numpy scikit-learn xgboost matplotlib seaborn scipy joblib -q\n",
        "\n",
        "print(\"âœ… All packages installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from scipy import stats\n",
        "from scipy.stats import mannwhitneyu, pearsonr\n",
        "\n",
        "# Google Colab file upload\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"âœ… All libraries imported successfully!\")\n",
        "print(f\"Running in {'Google Colab' if IN_COLAB else 'Local Jupyter'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load Master Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load master training dataset\n",
        "if IN_COLAB:\n",
        "    # Upload file in Colab\n",
        "    uploaded = files.upload()\n",
        "    df = pd.read_csv('master_training_dataset.csv')\n",
        "else:\n",
        "    # Load from local file\n",
        "    df = pd.read_csv('../senseai_backend/master_training_dataset.csv')\n",
        "\n",
        "print(f\"ðŸ“Š Dataset loaded: {len(df)} rows, {len(df.columns)} columns\")\n",
        "print(f\"\\nData sources: {df['data_source'].value_counts().to_dict()}\")\n",
        "print(f\"\\nGroups: {df['group'].value_counts().to_dict()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Data Exploration and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore data\n",
        "print(\"ðŸ“Š Data Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Missing Values:\")\n",
        "missing = df.isnull().sum().sort_values(ascending=False)\n",
        "print(missing[missing > 0])\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Target Distribution:\")\n",
        "print(df['group'].value_counts())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Data Source Distribution:\")\n",
        "print(df['data_source'].value_counts())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Age Distribution:\")\n",
        "if 'age_months' in df.columns:\n",
        "    print(df['age_months'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove rows with missing group (target variable)\n",
        "df = df[df['group'].notna()].copy()\n",
        "\n",
        "# Separate real and synthetic data\n",
        "real_data = df[df['data_source'] == 'real'].copy()\n",
        "synthetic_data = df[df['data_source'].isin(['synthetic_asd', 'synthetic_td'])].copy()\n",
        "\n",
        "print(f\"ðŸ“Š Real data: {len(real_data)} rows\")\n",
        "print(f\"ðŸ“Š Synthetic data: {len(synthetic_data)} rows\")\n",
        "print(f\"\\nReal data groups: {real_data['group'].value_counts().to_dict()}\")\n",
        "print(f\"Synthetic data groups: {synthetic_data['group'].value_counts().to_dict()}\")\n",
        "\n",
        "# Check for missing values in key columns\n",
        "print(f\"\\nMissing values in real data:\")\n",
        "print(real_data.isnull().sum()[real_data.isnull().sum() > 0].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Feature Engineering\n",
        "\n",
        "### 4.1: Calculate Derived Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate derived features if they don't exist\n",
        "print(\"ðŸ”§ Calculating derived features...\")\n",
        "\n",
        "# Switch cost (if not present)\n",
        "if 'switch_cost_ms' not in df.columns or df['switch_cost_ms'].isna().all():\n",
        "    if 'avg_rt_post_switch_correct_ms' in df.columns and 'avg_rt_pre_switch_ms' in df.columns:\n",
        "        df['switch_cost_ms'] = df['avg_rt_post_switch_correct_ms'] - df['avg_rt_pre_switch_ms']\n",
        "        print(\"   âœ… Calculated: switch_cost_ms\")\n",
        "\n",
        "# Accuracy drop (if not present)\n",
        "if 'accuracy_drop_percent' not in df.columns or df['accuracy_drop_percent'].isna().all():\n",
        "    if 'pre_switch_accuracy' in df.columns and 'post_switch_accuracy' in df.columns:\n",
        "        df['accuracy_drop_percent'] = df['pre_switch_accuracy'] - df['post_switch_accuracy']\n",
        "        print(\"   âœ… Calculated: accuracy_drop_percent\")\n",
        "\n",
        "# Commission error rate (if not present)\n",
        "if 'commission_error_rate' not in df.columns or df['commission_error_rate'].isna().all():\n",
        "    if 'nogo_accuracy' in df.columns:\n",
        "        df['commission_error_rate'] = 100 - df['nogo_accuracy']\n",
        "        print(\"   âœ… Calculated: commission_error_rate\")\n",
        "\n",
        "# RT variability (if not present)\n",
        "if 'rt_variability' not in df.columns or df['rt_variability'].isna().all():\n",
        "    if 'avg_reaction_time_ms' in df.columns:\n",
        "        # Use coefficient of variation as proxy\n",
        "        df['rt_variability'] = df['avg_reaction_time_ms'] * 0.15  # Approximate\n",
        "        print(\"   âœ… Estimated: rt_variability\")\n",
        "\n",
        "print(\"\\nâœ… Derived features calculated!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2: Age Normalization (Z-Scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Age normalization using control group norms\n",
        "print(\"ðŸ”§ Performing age normalization...\")\n",
        "\n",
        "# Get control group data (for establishing norms)\n",
        "control_df = df[df['group'] == 'typically_developing'].copy()\n",
        "\n",
        "# Features to normalize (age-sensitive features)\n",
        "features_to_normalize = [\n",
        "    'switch_cost_ms',\n",
        "    'perseverative_error_rate_post_switch',\n",
        "    'commission_error_rate',\n",
        "    'rt_variability',\n",
        "    'post_switch_accuracy',\n",
        "    'nogo_accuracy',\n",
        "    'avg_rt_pre_switch_ms',\n",
        "    'avg_rt_post_switch_correct_ms',\n",
        "    'avg_rt_go_ms',\n",
        "    'accuracy_drop_percent',\n",
        "    'go_accuracy',\n",
        "    'overall_accuracy'\n",
        "]\n",
        "\n",
        "# Filter to features that exist in dataset\n",
        "features_to_normalize = [f for f in features_to_normalize if f in df.columns]\n",
        "\n",
        "if len(features_to_normalize) > 0 and len(control_df) > 0:\n",
        "    print(f\"Normalizing {len(features_to_normalize)} features using control group norms...\")\n",
        "    \n",
        "    for feature in features_to_normalize:\n",
        "        z_scores = []\n",
        "        \n",
        "        for idx, row in df.iterrows():\n",
        "            age = row.get('age_months', 36)\n",
        "            value = row[feature]\n",
        "            \n",
        "            # Skip if missing\n",
        "            if pd.isna(value) or pd.isna(age):\n",
        "                z_scores.append(0)\n",
        "                continue\n",
        "            \n",
        "            # Find age-matched controls (Â±6 months window)\n",
        "            age_band_controls = control_df[\n",
        "                (control_df['age_months'] >= age - 6) & \n",
        "                (control_df['age_months'] <= age + 6)\n",
        "            ]\n",
        "            \n",
        "            if len(age_band_controls) > 1:\n",
        "                # Use age-matched controls\n",
        "                mean_val = age_band_controls[feature].mean()\n",
        "                std_val = age_band_controls[feature].std()\n",
        "                z_score = (value - mean_val) / std_val if std_val > 0 else 0\n",
        "            elif len(control_df) > 0:\n",
        "                # Fallback to all controls\n",
        "                mean_val = control_df[feature].mean()\n",
        "                std_val = control_df[feature].std()\n",
        "                z_score = (value - mean_val) / std_val if std_val > 0 else 0\n",
        "            else:\n",
        "                z_score = 0\n",
        "            \n",
        "            z_scores.append(z_score)\n",
        "        \n",
        "        # Create z-score column\n",
        "        df[f'{feature}_zscore'] = z_scores\n",
        "        print(f\"   âœ… Normalized: {feature} â†’ {feature}_zscore\")\n",
        "    \n",
        "    print(f\"\\nâœ… Age normalization completed!\")\n",
        "else:\n",
        "    print(\"âš ï¸  Skipping age normalization (no control data or features)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define feature candidates (aligned with your existing model)\n",
        "FEATURE_CANDIDATES = [\n",
        "    # Age\n",
        "    \"age_months\",\n",
        "    \n",
        "    # Cognitive Flexibility (DCCS) - Raw\n",
        "    \"post_switch_accuracy\",\n",
        "    \"pre_switch_accuracy\",\n",
        "    \"switch_cost_ms\",\n",
        "    \"avg_rt_pre_switch_ms\",\n",
        "    \"avg_rt_post_switch_correct_ms\",\n",
        "    \"accuracy_drop_percent\",\n",
        "    \"perseverative_error_rate_post_switch\",\n",
        "    \"cognitive_flexibility_score\",\n",
        "    \n",
        "    # Cognitive Flexibility (DCCS) - Z-scores\n",
        "    \"post_switch_accuracy_zscore\",\n",
        "    \"switch_cost_ms_zscore\",\n",
        "    \"avg_rt_pre_switch_ms_zscore\",\n",
        "    \"avg_rt_post_switch_correct_ms_zscore\",\n",
        "    \"accuracy_drop_percent_zscore\",\n",
        "    \"perseverative_error_rate_post_switch_zscore\",\n",
        "    \n",
        "    # Inhibitory Control (Go/No-Go) - Raw\n",
        "    \"go_accuracy\",\n",
        "    \"nogo_accuracy\",\n",
        "    \"commission_error_rate\",\n",
        "    \"omission_error_rate\",\n",
        "    \"inhibition_failure_rate\",\n",
        "    \n",
        "    # Inhibitory Control (Go/No-Go) - Z-scores\n",
        "    \"nogo_accuracy_zscore\",\n",
        "    \"go_accuracy_zscore\",\n",
        "    \"commission_error_rate_zscore\",\n",
        "    \n",
        "    # Reaction Time Metrics\n",
        "    \"avg_reaction_time_ms\",\n",
        "    \"rt_variability\",\n",
        "    \"rt_range\",\n",
        "    \"rt_variability_zscore\",\n",
        "    \"avg_rt_go_ms\",\n",
        "    \"avg_rt_go_ms_zscore\",\n",
        "    \n",
        "    # Behavioral Observations\n",
        "    \"attention_level\",\n",
        "    \"engagement_level\",\n",
        "    \"frustration_tolerance\",\n",
        "    \"instruction_following\",\n",
        "    \n",
        "    # Social Communication\n",
        "    \"social_communication_score\",\n",
        "    \"social_responsiveness_score\",\n",
        "    \"joint_attention_score\",\n",
        "    \n",
        "    # Task Performance\n",
        "    \"completion_time_sec\",\n",
        "    \"overall_accuracy\",\n",
        "    \"overall_accuracy_zscore\",\n",
        "]\n",
        "\n",
        "# Filter to features that exist in dataset\n",
        "available_features = [f for f in FEATURE_CANDIDATES if f in df.columns]\n",
        "missing_features = [f for f in FEATURE_CANDIDATES if f not in df.columns]\n",
        "\n",
        "print(f\"âœ… Available features: {len(available_features)}/{len(FEATURE_CANDIDATES)}\")\n",
        "print(f\"\\nAvailable features:\")\n",
        "for feat in available_features:\n",
        "    print(f\"  - {feat}\")\n",
        "\n",
        "if missing_features:\n",
        "    print(f\"\\nâš ï¸ Missing features (will be skipped):\")\n",
        "    for feat in missing_features[:10]:  # Show first 10\n",
        "        print(f\"  - {feat}\")\n",
        "    if len(missing_features) > 10:\n",
        "        print(f\"  ... and {len(missing_features) - 10} more\")\n",
        "\n",
        "# Use available features\n",
        "FEATURE_COLUMNS = available_features\n",
        "TARGET = \"group\"\n",
        "\n",
        "print(f\"\\nâœ… Using {len(FEATURE_COLUMNS)} features for training\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine real and synthetic data\n",
        "all_data = pd.concat([real_data, synthetic_data], ignore_index=True)\n",
        "\n",
        "# Select features and target\n",
        "X = all_data[FEATURE_COLUMNS].copy()\n",
        "y = all_data[TARGET].copy()\n",
        "data_source = all_data['data_source'].copy()\n",
        "\n",
        "# Handle missing values: Fill with median for numeric features\n",
        "print(\"ðŸ”§ Handling missing values...\")\n",
        "for col in FEATURE_COLUMNS:\n",
        "    if X[col].dtype in ['float64', 'int64']:\n",
        "        missing_count = X[col].isnull().sum()\n",
        "        if missing_count > 0:\n",
        "            median_val = X[col].median()\n",
        "            if pd.isna(median_val):\n",
        "                median_val = 0  # Fallback\n",
        "            X[col] = X[col].fillna(median_val)\n",
        "            print(f\"   Filled {col}: {missing_count} missing â†’ median={median_val:.2f}\")\n",
        "\n",
        "# Check remaining missing values\n",
        "remaining_missing = X.isnull().sum().sum()\n",
        "print(f\"\\nâœ… Remaining missing values: {remaining_missing}\")\n",
        "\n",
        "# Encode target variable\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "print(f\"\\nâœ… Target encoding:\")\n",
        "for i, class_name in enumerate(le.classes_):\n",
        "    print(f\"  {class_name} â†’ {i}\")\n",
        "\n",
        "print(f\"\\nâœ… Feature matrix shape: {X.shape}\")\n",
        "print(f\"âœ… Target distribution:\")\n",
        "print(pd.Series(y).value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Create Sample Weights (Real > Synthetic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample weights: Real data = 1.0, Synthetic = 0.3\n",
        "sample_weights = np.where(data_source == 'real', 1.0, 0.3)\n",
        "\n",
        "print(f\"ðŸ“Š Sample weights distribution:\")\n",
        "print(f\"  Real data (weight=1.0): {np.sum(sample_weights == 1.0)} samples\")\n",
        "print(f\"  Synthetic data (weight=0.3): {np.sum(sample_weights == 0.3)} samples\")\n",
        "print(f\"\\n  Total weighted samples: {np.sum(sample_weights):.1f}\")\n",
        "print(f\"  Effective real samples: {np.sum(sample_weights == 1.0)}\")\n",
        "print(f\"  Effective synthetic samples: {np.sum(sample_weights == 0.3) * 0.3:.1f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Train/Validation/Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split REAL data into train/val/test (70/15/15)\n",
        "real_indices = data_source[data_source == 'real'].index\n",
        "real_X = X.loc[real_indices]\n",
        "real_y = y_encoded[real_indices]\n",
        "\n",
        "# First split: 70% train, 30% temp (for val+test)\n",
        "X_train_real, X_temp, y_train_real, y_temp = train_test_split(\n",
        "    real_X, real_y, \n",
        "    test_size=0.3, \n",
        "    random_state=42, \n",
        "    stratify=real_y\n",
        ")\n",
        "\n",
        "# Second split: 50% val, 50% test (from temp)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "# Add ALL synthetic data to training set\n",
        "synthetic_indices = data_source[data_source != 'real'].index\n",
        "X_train_synthetic = X.loc[synthetic_indices]\n",
        "y_train_synthetic = y_encoded[synthetic_indices]\n",
        "weights_synthetic = sample_weights[synthetic_indices]\n",
        "\n",
        "# Combine real training data with synthetic\n",
        "X_train = pd.concat([X_train_real, X_train_synthetic], ignore_index=True)\n",
        "y_train = np.concatenate([y_train_real, y_train_synthetic])\n",
        "weights_train = np.concatenate([\n",
        "    np.ones(len(y_train_real)),  # Real data = 1.0\n",
        "    weights_synthetic  # Synthetic = 0.3\n",
        "])\n",
        "\n",
        "print(f\"ðŸ“Š Final Split:\")\n",
        "print(f\"  Training: {len(X_train)} samples ({len(X_train_real)} real + {len(X_train_synthetic)} synthetic)\")\n",
        "print(f\"  Validation: {len(X_val)} samples (real only)\")\n",
        "print(f\"  Test: {len(X_test)} samples (real only)\")\n",
        "print(f\"\\n  Training target distribution:\")\n",
        "print(f\"    {pd.Series(le.inverse_transform(y_train)).value_counts().to_dict()}\")\n",
        "print(f\"\\n  Validation target distribution:\")\n",
        "print(f\"    {pd.Series(le.inverse_transform(y_val)).value_counts().to_dict()}\")\n",
        "print(f\"\\n  Test target distribution:\")\n",
        "print(f\"    {pd.Series(le.inverse_transform(y_test)).value_counts().to_dict()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Feature Scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"âœ… Features scaled:\")\n",
        "print(f\"  Training: {X_train_scaled.shape}\")\n",
        "print(f\"  Validation: {X_val_scaled.shape}\")\n",
        "print(f\"  Test: {X_test_scaled.shape}\")\n",
        "print(f\"\\n  Feature means (should be ~0): {X_train_scaled.mean(axis=0)[:5]}\")\n",
        "print(f\"  Feature stds (should be ~1): {X_train_scaled.std(axis=0)[:5]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Train Logistic Regression Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Logistic Regression with sample weights\n",
        "model = LogisticRegression(\n",
        "    max_iter=2000,\n",
        "    class_weight='balanced',  # Handle class imbalance\n",
        "    random_state=42,\n",
        "    solver='lbfgs'  # Good for small-medium datasets\n",
        ")\n",
        "\n",
        "print(\"ðŸ”„ Training model...\")\n",
        "model.fit(X_train_scaled, y_train, sample_weight=weights_train)\n",
        "\n",
        "print(\"âœ… Model trained successfully!\")\n",
        "print(f\"\\nModel coefficients shape: {model.coef_.shape}\")\n",
        "print(f\"Model intercept: {model.intercept_}\")\n",
        "print(f\"Number of features: {len(FEATURE_COLUMNS)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Validation Set Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on validation set\n",
        "y_val_pred = model.predict(X_val_scaled)\n",
        "y_val_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "# Classification report\n",
        "print(\"ðŸ“Š VALIDATION SET RESULTS:\")\n",
        "print(\"=\" * 60)\n",
        "print(classification_report(y_val, y_val_pred, target_names=le.classes_))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_val, y_val_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title('Validation Set Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ROC-AUC\n",
        "if len(le.classes_) == 2:\n",
        "    auc = roc_auc_score(y_val, y_val_proba)\n",
        "    print(f\"\\nROC-AUC Score: {auc:.4f}\")\n",
        "    \n",
        "    fpr, tpr, _ = roc_curve(y_val, y_val_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.4f})', linewidth=2)\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Validation Set ROC Curve')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: FINAL TEST SET EVALUATION (Real Data Only)\n",
        "\n",
        "**This is what you report in your thesis!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on test set (REAL DATA ONLY - this is what you report!)\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "y_test_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "print(\"ðŸŽ¯ FINAL TEST SET RESULTS (REAL DATA ONLY)\")\n",
        "print(\"=\" * 60)\n",
        "print(\"This is what you report in your thesis!\")\n",
        "print(\"=\" * 60)\n",
        "print(classification_report(y_test, y_test_pred, target_names=le.classes_))\n",
        "\n",
        "# Confusion matrix\n",
        "cm_test = confusion_matrix(y_test, y_test_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens', \n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title('Test Set Confusion Matrix (Real Data Only)')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ROC-AUC\n",
        "if len(le.classes_) == 2:\n",
        "    auc_test = roc_auc_score(y_test, y_test_proba)\n",
        "    print(f\"\\nðŸŽ¯ FINAL TEST ROC-AUC Score: {auc_test:.4f}\")\n",
        "    \n",
        "    fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_test:.4f})', linewidth=2)\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Test Set ROC Curve (Real Data Only)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Feature importance (coefficients)\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': FEATURE_COLUMNS,\n",
        "    'coefficient': model.coef_[0],\n",
        "    'abs_coefficient': np.abs(model.coef_[0])\n",
        "}).sort_values('abs_coefficient', ascending=False)\n",
        "\n",
        "print(\"\\nðŸ“Š Top 15 Most Important Features:\")\n",
        "print(feature_importance.head(15).to_string(index=False))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
