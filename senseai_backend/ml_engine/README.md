# ğŸ§  SenseAI ML Engine

Professional FastAPI-based ML inference service for ASD screening predictions.

**Status:** âœ… Production-ready, research-grade, industry-standard

---

## ğŸ¯ Features

- âœ… **Professional Structure**: Modular, scalable, maintainable
- âœ… **Auto-Generated API Docs**: Swagger UI at `/docs`
- âœ… **Structured Logging**: Audit trail for clinical use
- âœ… **Centralized Configuration**: Reproducible, no hard-coded paths
- âœ… **Model Metadata**: Transparency and versioning
- âœ… **Feature Validation**: Safe error handling
- âœ… **Child ID Tracking**: Ethics compliance
- âœ… **Age Normalization**: Z-score calculation from control norms

---

## ğŸš€ Quick Start

### 1. Setup Virtual Environment

```bash
cd senseai_backend/ml_engine
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

**âš ï¸ Important:** `venv/` is in `.gitignore` - do NOT commit it. Use `requirements.txt` instead.

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Place Model Files

Copy your trained model files to `models/`:

```
models/
â”œâ”€â”€ asd_detection_model.pkl      (or asd_screening_model_calibrated.pkl)
â”œâ”€â”€ feature_scaler.pkl
â”œâ”€â”€ feature_names.json
â””â”€â”€ age_norms.json               (optional, for age normalization)
```

### 4. Run Service

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8001
```

Service will be available at:
- **API**: http://localhost:8001
- **Docs**: http://localhost:8001/docs (Swagger UI)
- **ReDoc**: http://localhost:8001/redoc

---

## ğŸ“‹ API Endpoints

### Health Check

```bash
GET /health
```

Returns service status and model availability.

### Prediction

```bash
POST /predict
```

**Request:**
```json
{
  "age_months": 48,
  "features": {
    "post_switch_accuracy": 65,
    "switch_cost_ms": 450,
    "perseverative_error_rate_post_switch": 35
  },
  "age_group": "4-5",
  "session_type": "color_shape"
}
```

**Response:**
```json
{
  "prediction": 1,
  "probability": [0.21, 0.79],
  "confidence": 0.79,
  "risk_level": "high",
  "risk_score": 78.9,
  "asd_probability": 0.789
}
```

---

## ğŸ§ª Testing

### Test with curl

```bash
curl -X POST http://localhost:8001/predict \
  -H "Content-Type: application/json" \
  -d '{
    "age_months": 48,
    "features": {
      "post_switch_accuracy": 65,
      "switch_cost_ms": 450
    }
  }'
```

### Test with Python

```python
import requests

response = requests.post(
    "http://localhost:8001/predict",
    json={
        "age_months": 48,
        "features": {
            "post_switch_accuracy": 65,
            "switch_cost_ms": 450
        }
    }
)
print(response.json())
```

---

## ğŸ”— Integration with Node.js Backend

Update `senseai_backend/routes/ml_predictions.js`:

```javascript
const axios = require('axios');

const ML_ENGINE_URL = process.env.ML_ENGINE_URL || 'http://localhost:8001';

router.post('/predict', async (req, res) => {
  try {
    const { mlFeatures, ageGroup, sessionType } = req.body;
    
    // Call FastAPI service
    const response = await axios.post(`${ML_ENGINE_URL}/predict`, {
      age_months: mlFeatures.age_months || 36,
      features: mlFeatures,
      age_group: ageGroup,
      session_type: sessionType
    });
    
    res.json({
      success: true,
      ...response.data,
      method: 'ml'
    });
  } catch (err) {
    // Fallback to rule-based
    return res.json(fallbackPrediction(mlFeatures));
  }
});
```

---

## ğŸ“ Project Structure

```
ml_engine/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ predict.py       # /predict endpoint
â”‚   â”‚   â””â”€â”€ health.py        # /health endpoint
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ model_loader.py  # Load models
â”‚   â”‚   â”œâ”€â”€ preprocessing.py # Age normalization
â”‚   â”‚   â””â”€â”€ predictor.py     # Prediction logic
â”‚   â””â”€â”€ schemas/
â”‚       â”œâ”€â”€ request.py       # Request schemas
â”‚       â””â”€â”€ response.py      # Response schemas
â”œâ”€â”€ models/                  # Model files go here
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âœ… Features

- âœ… Professional FastAPI structure
- âœ… Auto-generated API documentation (Swagger)
- âœ… Type-safe with Pydantic schemas
- âœ… Age normalization support
- âœ… Error handling
- âœ… Health checks
- âœ… CORS enabled for backend integration

---

## ğŸš€ Production Deployment

For production, use a process manager:

```bash
# Using gunicorn with uvicorn workers
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8001
```

Or use Docker, systemd, or your preferred deployment method.

---

## ğŸ“ Notes

- Models are loaded once at startup (cached)
- Age normalization is optional (works without age_norms.json)
- Feature count mismatch is handled automatically
- All errors return proper HTTP status codes
- Logs are saved to `logs/ml_engine.log`
- Model metadata is included in health check if available

---

## ğŸ” Logging

Logs are automatically saved to:
```
ml_engine/logs/ml_engine.log
```

View logs:
```bash
tail -f logs/ml_engine.log  # Linux/Mac
Get-Content logs/ml_engine.log -Wait  # Windows PowerShell
```

---

## ğŸ“Š Model Metadata

Create `models/model_metadata.json` for transparency:

```bash
cp models/model_metadata.json.example models/model_metadata.json
# Edit with your model information
```

This will be included in health check responses.

---

## âœ… Professional Improvements

See `README_IMPROVEMENTS.md` for details on:
- Centralized configuration
- Structured logging
- Model metadata
- Feature validation
- Child ID tracking

---

**Your professional ML engine is ready!** ğŸ‰

