{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Age 2–3.5 (Questionnaire) — Full Model Training + Testing (Google Colab)\n",
        "\n",
        "This notebook trains the **Age 2–3.5** autism screening model using:\n",
        "\n",
        "- **Training**: external questionnaire datasets (prepared CSV)\n",
        "- **Testing**: your hospital-collected questionnaire data (prepared CSV)\n",
        "\n",
        "It produces professional outputs:\n",
        "- ROC curves (CV folds + test)\n",
        "- Precision–Recall curve\n",
        "- Calibration curve\n",
        "- Confusion matrix\n",
        "- Feature importance (Logistic Regression coefficients)\n",
        "- Saved model artifacts (`.pkl` + `.json`) ready for your ML engine\n",
        "\n",
        "## What you must upload to Colab\n",
        "Upload a ZIP containing your project (recommended):\n",
        "- `Autism_Screening_Tool_25-26J-273.zip` **OR**\n",
        "- `ML_TRAINING.zip` + `SAMPLE_DATASETS.zip` (must include `SAMPLE_DATASETS/prepared/*.csv`)\n",
        "\n",
        "This notebook expects these prepared files:\n",
        "- `SAMPLE_DATASETS/prepared/train_age_2_3_5_external.csv`\n",
        "- `SAMPLE_DATASETS/prepared/test_age_2_3_5_hospital.csv`\n",
        "\n",
        "If they are missing, the notebook can run `ML_TRAINING/prepare_train_test_datasets.py` to generate them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Install dependencies\n",
        "!pip install -q pandas numpy scikit-learn matplotlib seaborn scipy joblib\n",
        "\n",
        "print('[OK] Packages installed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Upload and extract your project ZIP\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "print('Upload ONE zip (recommended): your full project zip')\n",
        "print('OR upload multiple zips: ML_TRAINING.zip + SAMPLE_DATASETS.zip + Online_Datasets.zip')\n",
        "uploaded = files.upload()\n",
        "\n",
        "for name in uploaded.keys():\n",
        "    if not name.lower().endswith('.zip'):\n",
        "        print('[WARN] Skipping non-zip:', name)\n",
        "        continue\n",
        "    with zipfile.ZipFile(name, 'r') as z:\n",
        "        z.extractall('/content')\n",
        "    print('[OK] Extracted:', name)\n",
        "\n",
        "print('[OK] Extraction done')\n",
        "print('Top-level /content folders:', [p.name for p in Path('/content').iterdir() if p.is_dir()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Auto-locate the project root and set working directory\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "content_root = Path('/content')\n",
        "\n",
        "# Find the folder that contains ML_TRAINING and SAMPLE_DATASETS\n",
        "ml_dirs = list(content_root.rglob('ML_TRAINING'))\n",
        "if not ml_dirs:\n",
        "    raise FileNotFoundError('ML_TRAINING folder not found under /content. Check your zip structure.')\n",
        "\n",
        "ml_dir = sorted(ml_dirs, key=lambda p: len(str(p)))[0]\n",
        "project_root = ml_dir.parent\n",
        "\n",
        "print('[OK] ML_TRAINING found at:', ml_dir)\n",
        "print('[OK] Project root assumed as:', project_root)\n",
        "\n",
        "# Check expected folders\n",
        "print('Has SAMPLE_DATASETS:', (project_root / 'SAMPLE_DATASETS').exists())\n",
        "print('Has Online Datasets:', (project_root / 'Online Datasets').exists())\n",
        "\n",
        "os.chdir(project_root)\n",
        "print('[OK] CWD:', os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Load prepared Train/Test CSVs (or generate them if missing)\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "train_path = Path('SAMPLE_DATASETS/prepared/train_age_2_3_5_external.csv')\n",
        "test_path = Path('SAMPLE_DATASETS/prepared/test_age_2_3_5_hospital.csv')\n",
        "\n",
        "if not train_path.exists() or not test_path.exists():\n",
        "    print('[WARN] Prepared CSVs not found. Generating them now...')\n",
        "    # This script reads from Online Datasets/ and hospital CSVs\n",
        "    # Make sure you uploaded those folders in your ZIP.\n",
        "    subprocess.run(['python', 'ML_TRAINING/prepare_train_test_datasets.py'], check=True)\n",
        "\n",
        "assert train_path.exists(), f'Missing: {train_path}'\n",
        "assert test_path.exists(), f'Missing: {test_path}'\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "print('[OK] Loaded training set:', train_df.shape)\n",
        "print('[OK] Loaded test set:', test_df.shape)\n",
        "\n",
        "print('\\nTraining class counts (group):')\n",
        "print(train_df['group'].value_counts(dropna=False))\n",
        "\n",
        "print('\\nTest class counts (group):')\n",
        "print(test_df['group'].value_counts(dropna=False))\n",
        "\n",
        "display(train_df.head(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Quick data QA + exploratory plots\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 4)\n",
        "\n",
        "FEATURES = [\n",
        "    'age_months',\n",
        "    'critical_items_failed',\n",
        "    'completion_time_sec',\n",
        "    'social_responsiveness_zscore',\n",
        "    'joint_attention_zscore',\n",
        "    'total_score_zscore',\n",
        "    'low_attention_flag',\n",
        "    'high_critical_items_flag',\n",
        "    'low_social_flag'\n",
        "]\n",
        "TARGET = 'group'\n",
        "\n",
        "# Basic checks\n",
        "print('[QA] Missing values (train):')\n",
        "print(train_df[FEATURES + [TARGET]].isna().sum())\n",
        "\n",
        "print('\\n[QA] Missing values (test):')\n",
        "print(test_df[FEATURES + [TARGET]].isna().sum())\n",
        "\n",
        "# Class balance plot\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
        "sns.countplot(x=TARGET, data=train_df, ax=ax[0])\n",
        "ax[0].set_title('Training class balance')\n",
        "\n",
        "sns.countplot(x=TARGET, data=test_df, ax=ax[1])\n",
        "ax[1].set_title('Test (hospital) class balance')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature distributions (train) for key features\n",
        "key_feats = ['critical_items_failed', 'social_responsiveness_zscore', 'total_score_zscore']\n",
        "fig, axes = plt.subplots(1, len(key_feats), figsize=(14, 3))\n",
        "for i, col in enumerate(key_feats):\n",
        "    sns.kdeplot(data=train_df, x=col, hue=TARGET, fill=True, common_norm=False, ax=axes[i])\n",
        "    axes[i].set_title(f'Train KDE: {col}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 6: Outlier handling (Winsorization on continuous features)\n",
        "# Clinical note: we cap extreme values instead of deleting children.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "CONTINUOUS = [\n",
        "    'age_months',\n",
        "    'critical_items_failed',\n",
        "    'completion_time_sec',\n",
        "    'social_responsiveness_zscore',\n",
        "    'joint_attention_zscore',\n",
        "    'total_score_zscore'\n",
        "]\n",
        "\n",
        "def winsorize_df(df, cols, lower_q=0.01, upper_q=0.99):\n",
        "    out = df.copy()\n",
        "    caps = {}\n",
        "    for c in cols:\n",
        "        lo = out[c].quantile(lower_q)\n",
        "        hi = out[c].quantile(upper_q)\n",
        "        out[c] = out[c].clip(lo, hi)\n",
        "        caps[c] = (float(lo), float(hi))\n",
        "    return out, caps\n",
        "\n",
        "# Boxplots before\n",
        "fig, axes = plt.subplots(1, 3, figsize=(14, 3))\n",
        "for ax, col in zip(axes, ['completion_time_sec','social_responsiveness_zscore','total_score_zscore']):\n",
        "    sns.boxplot(data=train_df, x=TARGET, y=col, ax=ax)\n",
        "    ax.set_title('Before: ' + col)\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "train_w, caps = winsorize_df(train_df, CONTINUOUS, 0.01, 0.99)\n",
        "print('[OK] Winsorization caps (1% / 99%):')\n",
        "for k,v in caps.items():\n",
        "    print(' -', k, v)\n",
        "\n",
        "# Boxplots after\n",
        "fig, axes = plt.subplots(1, 3, figsize=(14, 3))\n",
        "for ax, col in zip(axes, ['completion_time_sec','social_responsiveness_zscore','total_score_zscore']):\n",
        "    sns.boxplot(data=train_w, x=TARGET, y=col, ax=ax)\n",
        "    ax.set_title('After: ' + col)\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 7: Bootstrap augmentation to reduce class imbalance (training only)\n",
        "from sklearn.utils import resample\n",
        "\n",
        "X_train = train_w[FEATURES].copy()\n",
        "y_train = train_w[TARGET].astype(int).copy()\n",
        "\n",
        "counts = y_train.value_counts().to_dict()\n",
        "print('[INFO] Before augmentation counts:', counts)\n",
        "\n",
        "# Target: balance to the majority count\n",
        "maj = max(counts, key=counts.get)\n",
        "minc = min(counts, key=counts.get)\n",
        "\n",
        "n_target = counts[maj]\n",
        "\n",
        "df_train = X_train.copy()\n",
        "df_train[TARGET] = y_train\n",
        "\n",
        "df_maj = df_train[df_train[TARGET] == maj]\n",
        "df_min = df_train[df_train[TARGET] == minc]\n",
        "\n",
        "# Upsample minority\n",
        "min_up = resample(df_min, replace=True, n_samples=n_target, random_state=42)\n",
        "train_aug = pd.concat([df_maj, min_up], ignore_index=True).sample(frac=1, random_state=42)\n",
        "\n",
        "X_aug = train_aug[FEATURES]\n",
        "y_aug = train_aug[TARGET].astype(int)\n",
        "\n",
        "print('[OK] After augmentation counts:', y_aug.value_counts().to_dict())\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(4,3))\n",
        "sns.countplot(x=y_aug)\n",
        "plt.title('Augmented training class balance')\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 8: Cross-validated ROC curves (like your example figure)\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "X_cv = X_aug.values\n",
        "y_cv = y_aug.values\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "aucs = []\n",
        "for fold, (tr, va) in enumerate(cv.split(X_cv, y_cv)):\n",
        "    pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('lr', LogisticRegression(max_iter=2000, class_weight='balanced', solver='liblinear'))\n",
        "    ])\n",
        "    pipe.fit(X_cv[tr], y_cv[tr])\n",
        "    proba = pipe.predict_proba(X_cv[va])[:, 1]\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_cv[va], proba)\n",
        "    fold_auc = auc(fpr, tpr)\n",
        "    aucs.append(fold_auc)\n",
        "    plt.plot(fpr, tpr, label=f'ROC fold {fold} (AUC = {fold_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], '--', color='brown')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC curves (5-fold CV) — Age 2–3.5')\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('[OK] Mean CV AUC:', float(np.mean(aucs)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 9: Train final model on augmented training set + evaluate on hospital test set\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, roc_auc_score,\n",
        "    precision_recall_curve, average_precision_score\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "# Final pipeline\n",
        "final_model = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('lr', LogisticRegression(max_iter=2000, class_weight='balanced', solver='liblinear'))\n",
        "])\n",
        "\n",
        "final_model.fit(X_aug, y_aug)\n",
        "\n",
        "# Test evaluation\n",
        "X_test = test_df[FEATURES].copy()\n",
        "y_test = test_df[TARGET].astype(int).copy()\n",
        "\n",
        "y_proba = final_model.predict_proba(X_test)[:, 1]\n",
        "y_pred = (y_proba >= 0.5).astype(int)\n",
        "\n",
        "metrics = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred),\n",
        "    'precision': precision_score(y_test, y_pred, zero_division=0),\n",
        "    'recall': recall_score(y_test, y_pred, zero_division=0),\n",
        "    'f1': f1_score(y_test, y_pred, zero_division=0),\n",
        "    'roc_auc': roc_auc_score(y_test, y_proba) if len(set(y_test)) > 1 else None,\n",
        "    'pr_auc': average_precision_score(y_test, y_proba) if len(set(y_test)) > 1 else None,\n",
        "}\n",
        "\n",
        "print('[OK] Test metrics (hospital test set):')\n",
        "for k,v in metrics.items():\n",
        "    print(f' - {k}: {v}')\n",
        "\n",
        "print('\\nClassification report:')\n",
        "print(classification_report(y_test, y_pred, digits=3, zero_division=0))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(4,3))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Control','ASD'], yticklabels=['Control','ASD'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion matrix (hospital test)')\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "# ROC curve (test)\n",
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot(fpr, tpr, label=f\"Test ROC AUC = {metrics['roc_auc']:.2f}\")\n",
        "plt.plot([0,1],[0,1],'--', color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC (hospital test)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "# Precision-Recall curve (test)\n",
        "prec, rec, _ = precision_recall_curve(y_test, y_proba)\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot(rec, prec)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title(f\"Precision-Recall (AP = {metrics['pr_auc']:.2f})\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "# Calibration curve (test)\n",
        "frac_pos, mean_pred = calibration_curve(y_test, y_proba, n_bins=8)\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot(mean_pred, frac_pos, marker='o')\n",
        "plt.plot([0,1],[0,1],'--', color='gray')\n",
        "plt.xlabel('Mean predicted probability')\n",
        "plt.ylabel('Fraction of positives')\n",
        "plt.title('Calibration curve (hospital test)')\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 10: Feature importance (Logistic Regression coefficients)\n",
        "import pandas as pd\n",
        "\n",
        "lr = final_model.named_steps['lr']\n",
        "coef = lr.coef_.ravel()\n",
        "feat_imp = pd.DataFrame({'feature': FEATURES, 'coef': coef})\n",
        "feat_imp['abs_coef'] = feat_imp['coef'].abs()\n",
        "feat_imp = feat_imp.sort_values('abs_coef', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "sns.barplot(data=feat_imp, y='feature', x='coef')\n",
        "plt.axvline(0, color='black', linewidth=1)\n",
        "plt.title('Logistic Regression coefficients (direction of risk)')\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "display(feat_imp[['feature','coef']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 11: Save model artifacts (pkl + json) and download as ZIP\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "import json\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "import zipfile\n",
        "\n",
        "out_dir = Path('ML_TRAINING/models')\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "model_name = 'model_age_2_3_5_questionnaire_colab'\n",
        "\n",
        "model_path = out_dir / f'{model_name}.pkl'\n",
        "joblib.dump(final_model, model_path)\n",
        "\n",
        "features_path = out_dir / f'features_{model_name}.json'\n",
        "features_path.write_text(json.dumps(FEATURES, indent=2))\n",
        "\n",
        "metadata = {\n",
        "    'model_name': model_name,\n",
        "    'age_group': '2-3.5',\n",
        "    'train_file': str(train_path),\n",
        "    'test_file': str(test_path),\n",
        "    'features': FEATURES,\n",
        "    'algorithm': 'LogisticRegression (StandardScaler + LR pipeline)',\n",
        "    'trained_at': datetime.utcnow().isoformat() + 'Z',\n",
        "    'test_metrics': metrics,\n",
        "}\n",
        "metadata_path = out_dir / f'model_metadata_{model_name}.json'\n",
        "metadata_path.write_text(json.dumps(metadata, indent=2, default=str))\n",
        "\n",
        "print('[OK] Saved:')\n",
        "print(' -', model_path)\n",
        "print(' -', features_path)\n",
        "print(' -', metadata_path)\n",
        "\n",
        "zip_name = 'age_2_3_5_trained_model_and_reports.zip'\n",
        "with zipfile.ZipFile(zip_name, 'w') as z:\n",
        "    z.write(model_path)\n",
        "    z.write(features_path)\n",
        "    z.write(metadata_path)\n",
        "\n",
        "print('[OK] Created zip:', zip_name)\n",
        "files.download(zip_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 12: Predict for a NEW random child (example like your snippet)\n",
        "# IMPORTANT: the new child must provide the same FEATURES used by the model.\n",
        "\n",
        "new_child = {\n",
        "    'age_months': 30,\n",
        "    'critical_items_failed': 5,\n",
        "    'completion_time_sec': 360,\n",
        "    'social_responsiveness_zscore': 0.2,\n",
        "    'joint_attention_zscore': -0.4,\n",
        "    'total_score_zscore': 0.6,\n",
        "    'low_attention_flag': 1,\n",
        "    'high_critical_items_flag': 1,\n",
        "    'low_social_flag': 1,\n",
        "}\n",
        "\n",
        "new_child_df = pd.DataFrame([new_child])\n",
        "proba = final_model.predict_proba(new_child_df)[0]\n",
        "pred = int(final_model.predict(new_child_df)[0])\n",
        "\n",
        "print('PREDICTION RESULT')\n",
        "print('=' * 40)\n",
        "print('Diagnosis:', 'ASD RISK' if pred == 1 else 'No ASD concern')\n",
        "print('Confidence:', float(max(proba)))\n",
        "print('ASD Probability:', float(proba[1]))\n",
        "print('Control Probability:', float(proba[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (Optional) Dataset flow diagram (simple, paper-ready)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n_train = len(train_df)\n",
        "n_test = len(test_df)\n",
        "train_asd = int(train_df['group'].sum())\n",
        "train_ctrl = int(n_train - train_asd)\n",
        "test_asd = int(test_df['group'].sum())\n",
        "test_ctrl = int(n_test - test_asd)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 3))\n",
        "ax.axis('off')\n",
        "\n",
        "boxes = [\n",
        "    (0.05, 0.55, f\"External training set\\ntrain_age_2_3_5_external.csv\\nN={n_train} (ASD={train_asd}, Control={train_ctrl})\"),\n",
        "    (0.40, 0.55, \"Train LR model\\n(StandardScaler + LogisticRegression)\\n+ bootstrap balancing\"),\n",
        "    (0.75, 0.55, f\"Hospital test set\\ntest_age_2_3_5_hospital.csv\\nN={n_test} (ASD={test_asd}, Control={test_ctrl})\"),\n",
        "]\n",
        "\n",
        "for x, y, text in boxes:\n",
        "    ax.add_patch(plt.Rectangle((x, y), 0.22, 0.30, fill=False, linewidth=1.5))\n",
        "    ax.text(x + 0.11, y + 0.15, text, ha='center', va='center', fontsize=9)\n",
        "\n",
        "# arrows\n",
        "ax.annotate('', xy=(0.40, 0.70), xytext=(0.27, 0.70), arrowprops=dict(arrowstyle='->', lw=2))\n",
        "ax.annotate('', xy=(0.75, 0.70), xytext=(0.62, 0.70), arrowprops=dict(arrowstyle='->', lw=2))\n",
        "\n",
        "ax.text(0.515, 0.42, \"Evaluate: ROC / PR / Calibration / Confusion Matrix\", ha='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
